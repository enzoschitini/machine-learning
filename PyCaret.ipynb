{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduzione a PyCaret\n",
    "\n",
    "PyCaret è una libreria open-source per il machine learning che fornisce un ambiente integrato e facile da usare per il preprocessing, la modellazione, la valutazione e l'ottimizzazione di modelli di machine learning. Grazie alla sua semplicità, PyCaret consente agli utenti di creare modelli complessi con poche righe di codice, rendendolo ideale sia per i principianti che per gli esperti.\n",
    "\n",
    "## Perché usare PyCaret?\n",
    "\n",
    "- **Efficienza**: Permette di sperimentare con molteplici algoritmi in modo rapido.\n",
    "- **Semplicità**: Richiede una curva di apprendimento minima rispetto ad altre librerie di machine learning.\n",
    "- **Integrazione**: Funziona bene con strumenti di visualizzazione e di gestione dei dati come Pandas, Matplotlib e Seaborn.\n",
    "- **Automazione**: Automatizza molte delle fasi più complesse, come la selezione delle variabili, la ricerca dei parametri e la creazione di pipeline.\n",
    "\n",
    "## Installazione\n",
    "\n",
    "Per installare PyCaret, usa il seguente comando:\n",
    "\n",
    "```bash\n",
    "pip install pycaret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per utilizzare funzionalità specifiche come il deep learning o la gestione di dataset di grandi dimensioni, potresti dover installare ulteriori dipendenze.\n",
    "\n",
    "## Workflow di base con PyCaret\n",
    "\n",
    "### 1. Importare la libreria e caricare i dati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from pycaret.classification import *\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"dataset.csv\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Inizializzare l'ambiente\n",
    "\n",
    "Usa la funzione `setup` per preparare i dati per la modellazione. Questa funzione esegue operazioni come:\n",
    "\n",
    "- Trattamento dei valori nulli\n",
    "- Creazione di variabili dummy\n",
    "- Normalizzazione e scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "clf1 = setup(data, target='nome_colonna_target', session_id=123)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Confrontare i modelli\n",
    "\n",
    "La funzione `compare_models` confronta automaticamente i modelli disponibili e restituisce il migliore in base a metriche predefinite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "best_model = compare_models()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Creare e ottimizzare un modello\n",
    "\n",
    "Puoi creare un modello specifico con il comando `create_model` e ottimizzarlo con `tune_model`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "dt_model = create_model('dt')  # Decision Tree\n",
    "optimized_dt = tune_model(dt_model)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Valutare il modello\n",
    "\n",
    "Puoi visualizzare grafici e metriche con `evaluate_model`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "evaluate_model(optimized_dt)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Salvare il modello\n",
    "\n",
    "Puoi salvare il modello per un utilizzo futuro con:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "save_model(optimized_dt, 'optimized_decision_tree')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moduli principali\n",
    "\n",
    "PyCaret è organizzato in diversi moduli, ciascuno dedicato a un tipo specifico di problema:\n",
    "\n",
    "- `pycaret.classification`: Per problemi di classificazione.\n",
    "- `pycaret.regression`: Per problemi di regressione.\n",
    "- `pycaret.clustering`: Per il clustering.\n",
    "- `pycaret.anomaly`: Per la rilevazione di anomalie.\n",
    "\n",
    "## Esempio pratico: Classificazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from pycaret.classification import *\n",
    "\n",
    "# Caricamento dei dati\n",
    "data = pd.read_csv('credit_data.csv')\n",
    "\n",
    "# Configurazione\n",
    "clf1 = setup(data, target='default', session_id=123)\n",
    "\n",
    "# Confronto tra modelli\n",
    "best_model = compare_models()\n",
    "\n",
    "# Creazione di un modello\n",
    "rf_model = create_model('rf')\n",
    "\n",
    "# Ottimizzazione\n",
    "optimized_rf = tune_model(rf_model)\n",
    "\n",
    "# Valutazione\n",
    "evaluate_model(optimized_rf)\n",
    "\n",
    "# Salvare il modello\n",
    "save_model(optimized_rf, 'final_rf_model')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusioni\n",
    "\n",
    "PyCaret semplifica notevolmente il processo di sviluppo di modelli di machine learning, rendendolo accessibile a un pubblico più ampio. Grazie alla sua natura modulare, è possibile adattare PyCaret a una vasta gamma di applicazioni, rendendolo uno strumento prezioso per i data scientist e gli analisti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Caricare il dataset Titanic\n",
    "data = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Inizializzare l'Ambiente con PyCaret**\n",
    "\n",
    "La funzione `setup()` in PyCaret è il primo passo per iniziare una sessione di Machine Learning. Questa funzione prepara il dataset, applica la pre-elaborazione e configura l'ambiente per costruire modelli. È uno strumento potente e flessibile che consente di configurare molti aspetti della pipeline ML.\n",
    "\n",
    "\n",
    "### **Come funziona `setup()`?**\n",
    "\n",
    "Quando chiami `setup()`, PyCaret:\n",
    "\n",
    "1. Prepara i dati per l'analisi (es. gestione dei valori mancanti, codifica delle variabili categoriali).\n",
    "2. Configura la pipeline automatizzata per l'elaborazione.\n",
    "3. Definisce l'obiettivo (target) della predizione.\n",
    "4. Restituisce un ambiente configurato per il modeling.\n",
    "\n",
    "\n",
    "### **Sintassi Base**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import setup\n",
    "\n",
    "clf = setup(\n",
    "    data=data,              # Dataset come DataFrame Pandas\n",
    "    target='Survived',      # Variabile target\n",
    "    session_id=123          # Seed per la riproducibilità\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parametri Principali di `setup()`**\n",
    "\n",
    "1. **`data`** *(obbligatorio)*\n",
    "    \n",
    "    Il DataFrame Pandas che contiene il dataset.\n",
    "    \n",
    "2. **`target`** *(obbligatorio)*\n",
    "    \n",
    "    Nome della colonna che rappresenta la variabile target da prevedere.\n",
    "    \n",
    "3. **`session_id`** *(opzionale)*\n",
    "    \n",
    "    Un intero per garantire la riproducibilità dei risultati. Usare lo stesso seed genererà gli stessi risultati.\n",
    "    \n",
    "4. **`train_size`** *(default=0.7)*\n",
    "    \n",
    "    Percentuale di dati da utilizzare per il training. Il resto viene usato per il testing.\n",
    "    \n",
    "    ```python\n",
    "    train_size=0.8  # 80% per il training\n",
    "    \n",
    "    ```\n",
    "\n",
    "5. **`numeric_features`** *(opzionale)*\n",
    "    \n",
    "    Lista di colonne che devono essere trattate come numeriche, anche se il loro tipo non lo è.\n",
    "    \n",
    "    ```python\n",
    "    numeric_features=['Age', 'Fare']\n",
    "    \n",
    "    ```\n",
    "    \n",
    "6. **`categorical_features`** *(opzionale)*\n",
    "    \n",
    "    Lista di colonne da trattare come categoriali.\n",
    "    \n",
    "    ```python\n",
    "    categorical_features=['Pclass', 'Sex', 'Embarked']\n",
    "    \n",
    "    ```\n",
    "    \n",
    "7. **`ignore_features`** *(opzionale)*\n",
    "    \n",
    "    Colonne da escludere completamente dal processo di modellazione.\n",
    "    \n",
    "    ```python\n",
    "    ignore_features=['PassengerId', 'Name']\n",
    "    \n",
    "    ```\n",
    "    \n",
    "8. **`normalize`** *(default=False)*\n",
    "    \n",
    "    Se impostato a `True`, normalizza i dati numerici (es. Min-Max Scaling).\n",
    "    \n",
    "    ```python\n",
    "    normalize=True\n",
    "    \n",
    "    ```\n",
    "    \n",
    "9. **`imputation_type`** *(default=‘simple’)*\n",
    "    \n",
    "    Metodo di imputazione per valori mancanti:\n",
    "    \n",
    "    - `'simple'`: utilizza mediana/media/moda.\n",
    "    - `'iterative'`: utilizza tecniche iterative basate su regressione.\n",
    "10. **`feature_interaction`** *(default=False)*\n",
    "    \n",
    "    Se `True`, genera nuove feature basate su interazioni tra le colonne esistenti.\n",
    "\n",
    "### **Output di `setup()`**\n",
    "\n",
    "1. **Pipeline automatizzata:**\n",
    "Una pipeline completa con tutti i passi di pre-elaborazione.\n",
    "2. **Informazioni:**\n",
    "Una tabella riassuntiva che descrive cosa è stato fatto al dataset (es. normalizzazione, imputazione)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Esempio Completo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import setup\n",
    "\n",
    "clf = setup(\n",
    "    data=data,\n",
    "    target='Survived',\n",
    "    session_id=123,\n",
    "    train_size=0.8,\n",
    "    numeric_features=['Age', 'Fare'],\n",
    "    categorical_features=['Pclass', 'Sex', 'Embarked'],\n",
    "    ignore_features=['PassengerId', 'Name'],\n",
    "    normalize=True,\n",
    "    feature_interaction=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Confrontare i Modelli con PyCaret**\n",
    "\n",
    "Il passo di confronto dei modelli in PyCaret consente di valutare automaticamente una serie di algoritmi di machine learning e restituire il modello con le migliori prestazioni basandosi su metriche predefinite. Questa funzione è estremamente utile per identificare rapidamente un punto di partenza per il tuo progetto senza dover configurare ogni modello manualmente.\n",
    "\n",
    "### **Funzione Principale: `compare_models()`**\n",
    "\n",
    "La funzione `compare_models()` esegue diversi modelli di machine learning sul dataset pre-elaborato e li confronta utilizzando una metrica di valutazione principale.\n",
    "\n",
    "### **Sintassi Base**\n",
    "\n",
    "```python\n",
    "from pycaret.classification import *\n",
    "\n",
    "# Confrontare i modelli dopo aver configurato l'ambiente\n",
    "best_model = compare_models()\n",
    "\n",
    "```\n",
    "\n",
    "### **Parametri Principali di `compare_models()`**\n",
    "\n",
    "1. **`include`** *(opzionale)*\n",
    "    \n",
    "    Specifica un sottoinsieme di modelli da confrontare.\n",
    "    \n",
    "    Ad esempio, per confrontare solo la regressione logistica e l'albero decisionale:\n",
    "    \n",
    "    ```python\n",
    "    best_model = compare_models(include=['lr', 'dt'])\n",
    "    \n",
    "    ```\n",
    "    \n",
    "2. **`exclude`** *(opzionale)*\n",
    "    \n",
    "    Esclude determinati modelli dal confronto.\n",
    "    \n",
    "    Ad esempio, per escludere la regressione logistica:\n",
    "    \n",
    "    ```python\n",
    "    best_model = compare_models(exclude=['lr'])\n",
    "    \n",
    "    ```\n",
    "    \n",
    "3. **`fold`** *(default=10)*\n",
    "    \n",
    "    Numero di fold per la validazione incrociata (cross-validation).\n",
    "    \n",
    "    ```python\n",
    "    best_model = compare_models(fold=5)  # Usa 5 fold invece di 10\n",
    "    \n",
    "    ```\n",
    "    \n",
    "4. **`sort`** *(default='Accuracy')*\n",
    "    \n",
    "    Specifica la metrica utilizzata per ordinare i modelli. Opzioni comuni:\n",
    "    \n",
    "    - `Accuracy`\n",
    "    - `AUC`\n",
    "    - `Recall`\n",
    "    - `Precision`\n",
    "    - `F1`\n",
    "    - `Kappa`\n",
    "    \n",
    "    Ad esempio, per ordinare i modelli in base all'AUC:\n",
    "    \n",
    "    ```python\n",
    "    best_model = compare_models(sort='AUC')\n",
    "    \n",
    "    ```\n",
    "    \n",
    "5. **`n_select`** *(default=1)*\n",
    "    \n",
    "    Specifica il numero di migliori modelli da restituire.\n",
    "    \n",
    "    ```python\n",
    "    top3_models = compare_models(n_select=3)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "6. **`round`** *(default=4)*\n",
    "    \n",
    "    Specifica il numero di cifre decimali nei risultati.\n",
    "\n",
    "### **Output di `compare_models()`**\n",
    "\n",
    "1. **Miglior Modello:**\n",
    "    \n",
    "    Se `n_select=1` (default), restituisce il miglior modello basato sulla metrica specificata.\n",
    "    \n",
    "    ```python\n",
    "    print(best_model)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "2. **Lista di Modelli:**\n",
    "    \n",
    "    Se `n_select > 1`, restituisce una lista dei migliori modelli.\n",
    "    \n",
    "    ```python\n",
    "    top_models = compare_models(n_select=3)\n",
    "    for model in top_models:\n",
    "        print(model)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "3. **Tabella Riassuntiva:**\n",
    "    \n",
    "    Mostra una tabella con le metriche dei modelli testati (accuracy, AUC, ecc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Esempio Completo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "\n",
    "# Configurare l'ambiente\n",
    "clf = setup(data=data, target='Survived', session_id=123)\n",
    "\n",
    "# Confrontare i modelli basati sull'AUC, selezionando i primi 3\n",
    "top3_models = compare_models(sort='AUC', n_select=3)\n",
    "\n",
    "# Stampare i migliori modelli\n",
    "for model in top3_models:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Lista di Modelli Supportati**\n",
    "\n",
    "Alcuni esempi di modelli che puoi includere o escludere con `compare_models`:\n",
    "\n",
    "- **'lr'**: Logistic Regression\n",
    "- **'dt'**: Decision Tree\n",
    "- **'rf'**: Random Forest\n",
    "- **'knn'**: K-Nearest Neighbors\n",
    "- **'svm'**: Support Vector Machine\n",
    "- **'xgboost'**: Extreme Gradient Boosting\n",
    "- **'lightgbm'**: Light Gradient Boosting Machine\n",
    "\n",
    "La lista completa è disponibile nella documentazione ufficiale di PyCaret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Creare e Ottimizzare un Modello con PyCaret**\n",
    "\n",
    "In PyCaret, il processo di creazione e ottimizzazione dei modelli è progettato per essere intuitivo e potente. Con pochi comandi, puoi creare un modello machine learning e ottimizzarne le prestazioni personalizzandone gli iperparametri.\n",
    "\n",
    "### **Passo 1: Creare un Modello**\n",
    "\n",
    "La funzione `create_model()` permette di creare un'istanza di un modello specifico. Questo modello è addestrato utilizzando il dataset pre-elaborato definito nella funzione `setup()`.\n",
    "\n",
    "### **Sintassi Base**\n",
    "\n",
    "```python\n",
    "from pycaret.classification import *\n",
    "\n",
    "# Creare un modello Random Forest\n",
    "rf_model = create_model('rf')\n",
    "\n",
    "```\n",
    "\n",
    "### **Parametri Principali di `create_model()`**\n",
    "\n",
    "1. **`estimator`** *(obbligatorio)*\n",
    "    \n",
    "    Specifica il tipo di modello da creare utilizzando una stringa (es. `'rf'` per Random Forest, `'lr'` per Logistic Regression, ecc.).\n",
    "    \n",
    "    Ad esempio:\n",
    "    \n",
    "    ```python\n",
    "    lr_model = create_model('lr')  # Logistic Regression\n",
    "    \n",
    "    ```\n",
    "    \n",
    "2. **`fold`** *(default=10)*\n",
    "    \n",
    "    Numero di fold per la validazione incrociata (cross-validation).\n",
    "    \n",
    "    ```python\n",
    "    rf_model = create_model('rf', fold=5)  # Usa 5 fold\n",
    "    \n",
    "    ```\n",
    "    \n",
    "3. **`round`** *(default=4)*\n",
    "    \n",
    "    Numero di cifre decimali nelle metriche.\n",
    "    \n",
    "4. **`fit_kwargs`** *(opzionale)*\n",
    "    \n",
    "    Permette di passare parametri addizionali alla funzione `fit()` del modello.\n",
    "    \n",
    "5. **`verbose`** *(default=True)*\n",
    "    \n",
    "    Se impostato a `False`, disabilita la stampa dei risultati durante l'esecuzione.\n",
    "    \n",
    "\n",
    "### **Output di `create_model()`**\n",
    "\n",
    "- Restituisce un oggetto del modello addestrato, pronto per ulteriori analisi o ottimizzazioni.\n",
    "\n",
    "### **Passo 2: Ottimizzare un Modello**\n",
    "\n",
    "La funzione `tune_model()` è utilizzata per ottimizzare automaticamente gli iperparametri del modello creato.\n",
    "\n",
    "### **Sintassi Base**\n",
    "\n",
    "```python\n",
    "# Ottimizzare un modello Random Forest\n",
    "tuned_rf_model = tune_model(rf_model)\n",
    "\n",
    "```\n",
    "\n",
    "### **Parametri Principali di `tune_model()`**\n",
    "\n",
    "1. **`model`** *(obbligatorio)*\n",
    "    \n",
    "    L'oggetto del modello creato con `create_model()`.\n",
    "    \n",
    "2. **`optimize`** *(default='Accuracy')*\n",
    "    \n",
    "    Specifica la metrica da ottimizzare. Opzioni comuni:\n",
    "    \n",
    "    - `Accuracy`\n",
    "    - `AUC`\n",
    "    - `Recall`\n",
    "    - `Precision`\n",
    "    - `F1`\n",
    "    \n",
    "    Ad esempio:\n",
    "    \n",
    "    ```python\n",
    "    tuned_model = tune_model(rf_model, optimize='AUC')\n",
    "    \n",
    "    ```\n",
    "    \n",
    "3. **`custom_grid`** *(opzionale)*\n",
    "    \n",
    "    Specifica una griglia personalizzata di iperparametri per l'ottimizzazione.\n",
    "    \n",
    "    ```python\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    custom_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30]\n",
    "    }\n",
    "    \n",
    "    tuned_rf_model = tune_model(rf_model, custom_grid=custom_grid)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "4. **`fold`** *(default=10)*\n",
    "    \n",
    "    Numero di fold per la validazione incrociata durante l'ottimizzazione.\n",
    "    \n",
    "5. **`verbose`** *(default=True)*\n",
    "    \n",
    "    Se impostato a `False`, disabilita la stampa dei dettagli durante l'ottimizzazione.\n",
    "    \n",
    "\n",
    "### **Output di `tune_model()`**\n",
    "\n",
    "- Restituisce un modello con i migliori iperparametri trovati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Esempio Completo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "\n",
    "# Configurare l'ambiente\n",
    "clf = setup(data=data, target='Survived', session_id=123)\n",
    "\n",
    "# Creare un modello Random Forest\n",
    "rf_model = create_model('rf')\n",
    "\n",
    "# Ottimizzare il modello\n",
    "optimized_rf_model = tune_model(rf_model, optimize='AUC')\n",
    "\n",
    "# Stampare il modello ottimizzato\n",
    "print(optimized_rf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Valutare il Modello con PyCaret**\n",
    "\n",
    "La valutazione del modello è un passo fondamentale in ogni progetto di machine learning. PyCaret offre strumenti semplici ma potenti per esaminare le prestazioni del modello tramite metriche standard e visualizzazioni intuitive.\n",
    "\n",
    "### **Passo 1: Valutare il Modello Creato**\n",
    "\n",
    "La funzione `evaluate_model()` fornisce un'interfaccia interattiva per analizzare il modello, permettendo di visualizzare le principali metriche e grafici di performance.\n",
    "\n",
    "### **Sintassi Base**\n",
    "\n",
    "```python\n",
    "from pycaret.classification import *\n",
    "\n",
    "# Valutare un modello Random Forest\n",
    "evaluate_model(rf_model)\n",
    "\n",
    "```\n",
    "\n",
    "Questa funzione apre un'interfaccia grafica nel notebook o nell'ambiente interattivo in cui puoi scegliere diverse visualizzazioni.\n",
    "\n",
    "### **Passo 2: Visualizzare Metriche Specifiche**\n",
    "\n",
    "La funzione `plot_model()` è utilizzata per creare grafici specifici che rappresentano le prestazioni del modello. Supporta diverse visualizzazioni.\n",
    "\n",
    "### **Sintassi Base**\n",
    "\n",
    "```python\n",
    "plot_model(model, plot='plot_type')\n",
    "\n",
    "```\n",
    "\n",
    "### **Tipi di Grafici Disponibili**\n",
    "\n",
    "1. **`auc`**\n",
    "    \n",
    "    Curva ROC e AUC (Area Under the Curve).\n",
    "    \n",
    "    ```python\n",
    "    plot_model(rf_model, plot='auc')\n",
    "    \n",
    "    ```\n",
    "    \n",
    "2. **`confusion_matrix`**\n",
    "    \n",
    "    Matrice di confusione per visualizzare predizioni corrette e errate.\n",
    "    \n",
    "    ```python\n",
    "    plot_model(rf_model, plot='confusion_matrix')\n",
    "    \n",
    "    ```\n",
    "    \n",
    "3. **`feature`**\n",
    "    \n",
    "    Importanza delle variabili.\n",
    "    \n",
    "    ```python\n",
    "    plot_model(rf_model, plot='feature')\n",
    "    \n",
    "    ```\n",
    "    \n",
    "4. **`pr`**\n",
    "    \n",
    "    Precision-Recall Curve.\n",
    "    \n",
    "    ```python\n",
    "    plot_model(rf_model, plot='pr')\n",
    "    \n",
    "    ```\n",
    "    \n",
    "5. **`error`**\n",
    "    \n",
    "    Analisi degli errori di classificazione.\n",
    "    \n",
    "    ```python\n",
    "    plot_model(rf_model, plot='error')\n",
    "    \n",
    "    ```\n",
    "    \n",
    "6. **`class_report`**\n",
    "    \n",
    "    Report di classificazione dettagliato (precisione, recall, F1-score).\n",
    "    \n",
    "    ```python\n",
    "    plot_model(rf_model, plot='class_report')\n",
    "    \n",
    "    ```\n",
    "    \n",
    "7. **`learning`**\n",
    "    \n",
    "    Curva di apprendimento per analizzare il comportamento del modello durante l'addestramento.\n",
    "    \n",
    "    ```python\n",
    "    plot_model(rf_model, plot='learning')\n",
    "    \n",
    "    ```\n",
    "    \n",
    "8. **`calibration`**\n",
    "    \n",
    "    Calibrazione della probabilità predetta.\n",
    "    \n",
    "    ```python\n",
    "    plot_model(rf_model, plot='calibration')\n",
    "    \n",
    "    ```\n",
    "    \n",
    "9. **`vc`**\n",
    "    \n",
    "    Visualizzazione del clustering nei dati (valido solo per problemi di clustering).\n",
    "\n",
    "### **Passo 3: Valutare il Modello su un Dataset di Test**\n",
    "\n",
    "La funzione `predict_model()` permette di generare predizioni su un nuovo dataset e valutare le performance del modello su dati mai visti.\n",
    "\n",
    "### **Sintassi Base**\n",
    "\n",
    "```python\n",
    "# Predizioni e valutazione sul dataset di test\n",
    "predictions = predict_model(rf_model, data=test_data)\n",
    "\n",
    "```\n",
    "\n",
    "### **Parametri Principali di `predict_model()`**\n",
    "\n",
    "1. **`model`** *(obbligatorio)*\n",
    "    \n",
    "    Il modello addestrato e/o ottimizzato.\n",
    "    \n",
    "2. **`data`** *(opzionale)*\n",
    "    \n",
    "    Il dataset su cui effettuare le predizioni. Se non specificato, usa i dati di test definiti nel setup.\n",
    "    \n",
    "3. **`raw_score`** *(default=False)*\n",
    "    \n",
    "    Se impostato a `True`, restituisce anche i punteggi grezzi (es. probabilità).\n",
    "    \n",
    "4. **`verbose`** *(default=True)*\n",
    "    \n",
    "    Se impostato a `False`, non stampa i risultati intermedi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Esempio Completo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "\n",
    "# Configurare l'ambiente\n",
    "clf = setup(data=data, target='Survived', session_id=123)\n",
    "\n",
    "# Creare un modello\n",
    "rf_model = create_model('rf')\n",
    "\n",
    "# Valutare il modello interattivamente\n",
    "evaluate_model(rf_model)\n",
    "\n",
    "# Visualizzare la matrice di confusione\n",
    "plot_model(rf_model, plot='confusion_matrix')\n",
    "\n",
    "# Generare predizioni su dati di test\n",
    "predictions = predict_model(rf_model, data=test_data)\n",
    "\n",
    "# Stampare alcune predizioni\n",
    "print(predictions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Salvare il Modello con PyCaret**\n",
    "\n",
    "Salvare il modello è un passaggio essenziale per rendere riutilizzabile il lavoro svolto. PyCaret offre funzionalità integrate per salvare e caricare modelli, rendendo il processo semplice e veloce.\n",
    "\n",
    "### **Passo 1: Salvare un Modello**\n",
    "\n",
    "PyCaret fornisce il metodo `save_model()` per salvare un modello in formato pickle (.pkl), che può essere facilmente caricato e riutilizzato in futuro.\n",
    "\n",
    "### **Sintassi Base**\n",
    "\n",
    "```python\n",
    "save_model(model, model_name='model_name')\n",
    "\n",
    "```\n",
    "\n",
    "- **`model`** *(obbligatorio)*: Il modello che desideri salvare.\n",
    "- **`model_name`** *(opzionale)*: Il nome del file (senza estensione). Se non specificato, viene utilizzato un nome predefinito.\n",
    "\n",
    "### **Esempio**\n",
    "\n",
    "```python\n",
    "from pycaret.classification import *\n",
    "\n",
    "# Creare un modello\n",
    "rf_model = create_model('rf')\n",
    "\n",
    "# Salvare il modello\n",
    "save_model(rf_model, model_name='random_forest_model')\n",
    "\n",
    "```\n",
    "\n",
    "Questo salverà il modello nel file `random_forest_model.pkl` nella directory di lavoro corrente.\n",
    "\n",
    "### **Passo 2: Caricare un Modello Salvato**\n",
    "\n",
    "Per riutilizzare un modello salvato, PyCaret fornisce la funzione `load_model()`, che carica il file pickle precedentemente salvato.\n",
    "\n",
    "### **Sintassi Base**\n",
    "\n",
    "```python\n",
    "load_model(model_name='model_name')\n",
    "\n",
    "```\n",
    "\n",
    "- **`model_name`** *(obbligatorio)*: Il nome del file del modello salvato (senza estensione).\n",
    "\n",
    "### **Esempio**\n",
    "\n",
    "```python\n",
    "# Caricare un modello salvato\n",
    "loaded_model = load_model('random_forest_model')\n",
    "\n",
    "# Usare il modello caricato per fare predizioni\n",
    "predictions = predict_model(loaded_model, data=new_data)\n",
    "\n",
    "```\n",
    "\n",
    "### **Passo 3: Salvare e Caricare Pipeline Completa**\n",
    "\n",
    "Quando si salva un modello, PyCaret salva automaticamente l'intera pipeline, inclusi i passaggi di preprocessamento e il modello stesso. Questo garantisce che il modello funzioni esattamente come durante il training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Esempio Completo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "\n",
    "# Configurare l'ambiente\n",
    "clf = setup(data=data, target='Survived', session_id=123)\n",
    "\n",
    "# Creare un modello\n",
    "rf_model = create_model('rf')\n",
    "\n",
    "# Salvare il modello\n",
    "save_model(rf_model, model_name='final_rf_model')\n",
    "\n",
    "# Caricare il modello salvato\n",
    "final_model = load_model('final_rf_model')\n",
    "\n",
    "# Predizioni su nuovi dati\n",
    "new_predictions = predict_model(final_model, data=new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Metodi Principali dell'Ambiente Creato**\n",
    "\n",
    "Dopo `setup()`, puoi usare diversi metodi per esplorare i dati e costruire modelli:\n",
    "\n",
    "1. **`compare_models()`**\n",
    "    \n",
    "    Confronta i modelli disponibili e restituisce il migliore.\n",
    "    \n",
    "    ```python\n",
    "    best_model = compare_models()\n",
    "    \n",
    "    ```\n",
    "    \n",
    "2. **`create_model('model_name')`**\n",
    "    \n",
    "    Crea un modello specifico (es. `logistic`, `rf`).\n",
    "    \n",
    "    ```python\n",
    "    logistic_model = create_model('lr')  # Regressione logistica\n",
    "    \n",
    "    ```\n",
    "    \n",
    "3. **`tune_model()`**\n",
    "    \n",
    "    Ottimizza gli iperparametri di un modello.\n",
    "    \n",
    "    ```python\n",
    "    tuned_model = tune_model(logistic_model)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "4. **`plot_model()`**\n",
    "    \n",
    "    Genera grafici diagnostici per il modello.\n",
    "    \n",
    "    ```python\n",
    "    plot_model(tuned_model, plot='confusion_matrix')\n",
    "    \n",
    "    ```\n",
    "    \n",
    "5. **`finalize_model()`**\n",
    "    \n",
    "    Prepara il modello per la produzione.\n",
    "    \n",
    "    ```python\n",
    "    final_model = finalize_model(tuned_model)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "\n",
    "---\n",
    "\n",
    "### **Buone Pratiche**\n",
    "\n",
    "- Usa sempre `session_id` per garantire riproducibilità.\n",
    "- Identifica chiaramente i tipi di variabili (`numeric_features`, `categorical_features`).\n",
    "- Inizia con `compare_models()` per trovare rapidamente un punto di partenza.\n",
    "\n",
    "Se hai domande su uno specifico parametro o funzione, posso approfondire!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

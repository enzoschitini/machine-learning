{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Techniques\n",
    "Os algoritmos de ensemble são técnicas de machine learning que combinam vários modelos base para melhorar o desempenho geral do sistema. A ideia é que, ao agregar as previsões de diferentes modelos, obtém-se uma estimativa mais robusta e precisa em comparação com aquela fornecida por um único modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem diferentes tipos de algoritmos de ensemble, mas os principais são:\n",
    "\n",
    "- **Bagging (Bootstrap Aggregating)**:\n",
    "    - **Princípio**: Constrói vários modelos base em subconjuntos aleatórios dos dados de treinamento. Cada subconjunto é obtido usando o método bootstrap (amostragem com reposição).\n",
    "    - **Modelos Típicos**: Random Forest é um exemplo popular de bagging, utilizando decision trees como modelo base.\n",
    "    - **Vantagem**: Reduz a variância do modelo, melhorando a estabilidade e a precisão sem aumentar significativamente o bias.\n",
    "- **Boosting**:\n",
    "    - **Princípio**: Constrói os modelos base um de cada vez, com cada modelo focando nos erros dos modelos anteriores. Os modelos são treinados em sequência, e cada um melhora o anterior.\n",
    "    - **Modelos Típicos**: AdaBoost, Gradient Boosting, XGBoost, LightGBM e CatBoost.\n",
    "    - **Vantagem**: Melhora a precisão reduzindo tanto o bias quanto a variância. É particularmente eficaz em problemas de classificação e regressão.\n",
    "- **Stacking (Stacked Generalization)**:\n",
    "    - **Princípio**: Combina diferentes modelos base em um nível superior por meio de um meta-modelo. Os modelos base produzem suas previsões, que são usadas como entrada para o meta-modelo.\n",
    "    - **Modelo Típico**: Um exemplo é um classificador linear que usa as saídas de vários modelos base como entrada.\n",
    "    - **Vantagem**: Permite aproveitar os pontos fortes de diferentes modelos para obter previsões mais precisas.\n",
    "- **Blending**:\n",
    "    - **Princípio**: Similar ao stacking, mas utiliza um conjunto de validação separado para treinar o meta-modelo. Não usa o conjunto de teste na criação do modelo.\n",
    "    - **Vantagem**: É mais simples de implementar em comparação com o stacking e reduz o risco de overfitting no conjunto de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vantagens dos Algoritmos de Ensemble:\n",
    "\n",
    "- **Melhoria da Precisão**: Ao agregar vários modelos, tende-se a reduzir o erro global.\n",
    "- **Robustez**: Os modelos de ensemble são menos suscetíveis ao overfitting em comparação com modelos individuais.\n",
    "- **Flexibilidade**: Podem combinar modelos de diferentes tipos, aproveitando suas características complementares.\n",
    "\n",
    "### Desvantagens:\n",
    "\n",
    "- **Complexidade Computacional**: Os algoritmos de ensemble podem ser mais complexos e demandar mais recursos computacionais.\n",
    "- **Dificuldade na Interpretabilidade**: Como combinam vários modelos, pode ser difícil interpretar o comportamento geral do sistema.\n",
    "\n",
    "Em resumo, os algoritmos de ensemble são uma estratégia poderosa para melhorar o desempenho dos modelos de machine learning, aproveitando a diversidade e a sinergia entre diferentes modelos base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diferença entre algoritmos de Bagging e Boosting:\n",
    "\n",
    "Os métodos de Bagging e Boosting são ambos técnicas de ensemble learning utilizadas para melhorar o desempenho dos modelos de machine learning. No entanto, **diferem significativamente na forma como combinam os modelos base** (frequentemente chamados de \"weak learners\" ou \"base learners\") para criar um modelo mais robusto e preciso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
